{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "tgBWjBgAjPsx",
      "metadata": {
        "id": "tgBWjBgAjPsx"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "r4Dws2K6l9J2",
      "metadata": {
        "id": "r4Dws2K6l9J2"
      },
      "outputs": [],
      "source": [
        "url = '/content/drive/MyDrive/Colab Notebooks/DL/Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3b7f90bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:42.652671Z",
          "iopub.status.busy": "2023-06-14T14:27:42.652393Z",
          "iopub.status.idle": "2023-06-14T14:27:42.662330Z",
          "shell.execute_reply": "2023-06-14T14:27:42.661432Z"
        },
        "id": "3b7f90bf",
        "papermill": {
          "duration": 0.021055,
          "end_time": "2023-06-14T14:27:42.664736",
          "exception": false,
          "start_time": "2023-06-14T14:27:42.643681",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def split_data(dataset_dir, train_dir, val_dir, test_dir, split_ratio=(0.8, 0.1, 0.1)):\n",
        "    # If the directory already exists, delete it\n",
        "    for directory in [train_dir, val_dir, test_dir]:\n",
        "        if os.path.exists(directory):\n",
        "            shutil.rmtree(directory)\n",
        "\n",
        "    # Create the directory if it does not exist\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    # Collect the filenames\n",
        "    image_files = os.listdir(dataset_dir)\n",
        "    random.shuffle(image_files)\n",
        "\n",
        "    # Split the data\n",
        "    total_images = len(image_files)\n",
        "    num_train = int(total_images * split_ratio[0])\n",
        "    num_val = int(total_images * split_ratio[1])\n",
        "    num_test = total_images - num_train - num_val\n",
        "\n",
        "    # Copy the images to the correct directory\n",
        "    for i, image_file in enumerate(image_files):\n",
        "        src_path = os.path.join(dataset_dir, image_file)\n",
        "        if i < num_train:\n",
        "            dst_path = os.path.join(train_dir, image_file)\n",
        "        elif i < num_train + num_val:\n",
        "            dst_path = os.path.join(val_dir, image_file)\n",
        "        else:\n",
        "            dst_path = os.path.join(test_dir, image_file)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "    print(\"Splitting data completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f215ad7b",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:02.945130Z",
          "iopub.status.busy": "2023-06-14T14:27:02.944673Z",
          "iopub.status.idle": "2023-06-14T14:27:10.111044Z",
          "shell.execute_reply": "2023-06-14T14:27:10.110033Z"
        },
        "id": "f215ad7b",
        "papermill": {
          "duration": 7.180832,
          "end_time": "2023-06-14T14:27:10.113790",
          "exception": false,
          "start_time": "2023-06-14T14:27:02.932958",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "daff2232",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:42.681780Z",
          "iopub.status.busy": "2023-06-14T14:27:42.681519Z",
          "iopub.status.idle": "2023-06-14T14:27:44.232899Z",
          "shell.execute_reply": "2023-06-14T14:27:44.231705Z"
        },
        "id": "daff2232",
        "outputId": "4da772fc-6efd-4063-9a47-b5972102ed55",
        "papermill": {
          "duration": 1.563906,
          "end_time": "2023-06-14T14:27:44.236454",
          "exception": false,
          "start_time": "2023-06-14T14:27:42.672548",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitting data completed.\n",
            "Splitting data completed.\n",
            "Splitting data completed.\n"
          ]
        }
      ],
      "source": [
        "# Define paths\n",
        "black_pod_rot_SRC_DIR = \"data/black_pod_rot\"\n",
        "monilia_SRC_DIR = \"data/monilia\"\n",
        "healthy_SRC_DIR = \"data/healthy\"\n",
        "\n",
        "TRAINING_DIR = \"data/training\"\n",
        "VALIDATION_DIR = \"data/validation\"\n",
        "TEST_DIR = \"data/test\"\n",
        "\n",
        "TRAINING_BPR_DIR = os.path.join(TRAINING_DIR, \"black_pod_rot/\")\n",
        "VALIDATION_BPR_DIR = os.path.join(VALIDATION_DIR, \"black_pod_rot/\")\n",
        "TEST_BPR_DIR = os.path.join(TEST_DIR, \"black_pod_rot/\")\n",
        "\n",
        "TRAINING_M_DIR = os.path.join(TRAINING_DIR, \"monilia/\")\n",
        "VALIDATION_M_DIR = os.path.join(VALIDATION_DIR, \"monilia/\")\n",
        "TEST_M_DIR = os.path.join(TEST_DIR, \"monilia/\")\n",
        "\n",
        "TRAINING_HEALTHY_DIR = os.path.join(TRAINING_DIR, \"healthy/\")\n",
        "VALIDATION_HEALTHY_DIR = os.path.join(VALIDATION_DIR, \"healthy/\")\n",
        "TEST_HEALTHY_DIR = os.path.join(TEST_DIR, \"healthy/\")\n",
        "\n",
        "# Define proportion of images used for training\n",
        "train_size = 0.8\n",
        "val_size = 0.1\n",
        "test_size = 0.1\n",
        "\n",
        "split_data(black_pod_rot_SRC_DIR,\n",
        "           TRAINING_BPR_DIR,\n",
        "           VALIDATION_BPR_DIR,\n",
        "           TEST_BPR_DIR,\n",
        "           split_ratio=(train_size,val_size, test_size))\n",
        "\n",
        "split_data(healthy_SRC_DIR,\n",
        "           TRAINING_HEALTHY_DIR,\n",
        "           VALIDATION_HEALTHY_DIR,\n",
        "           TEST_HEALTHY_DIR,\n",
        "           split_ratio=(train_size,val_size, test_size))\n",
        "\n",
        "split_data(monilia_SRC_DIR,\n",
        "           TRAINING_M_DIR,\n",
        "           VALIDATION_M_DIR,\n",
        "           TEST_M_DIR,\n",
        "           split_ratio=(train_size,val_size, test_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "858bc130",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:44.285158Z",
          "iopub.status.busy": "2023-06-14T14:27:44.284666Z",
          "iopub.status.idle": "2023-06-14T14:27:44.306250Z",
          "shell.execute_reply": "2023-06-14T14:27:44.305173Z"
        },
        "id": "858bc130",
        "papermill": {
          "duration": 0.052866,
          "end_time": "2023-06-14T14:27:44.309470",
          "exception": false,
          "start_time": "2023-06-14T14:27:44.256604",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original Black Pod Rot directory has 943 images\n",
            "Original Healthy directory has 3344 images\n",
            "Original Monilia directory has 105 images\n",
            "\n",
            "There are 754 images of Black Pod Rot for training\n",
            "There are 2675 images ofHealthy for training\n",
            "There are 84 images of Monilia for training\n",
            "\n",
            "There are 94 images of Black Pod Rot for validation\n",
            "There are 334 images of Healthy for validation\n",
            "There are 10 images of Monilia for validation\n",
            "\n",
            "There are 95 images of Black Pod Rot for test\n",
            "There are 335 images of Healthy for test\n",
            "There are 11 images of Monilia for test\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"\\n\\nOriginal Black Pod Rot directory has {len(os.listdir(black_pod_rot_SRC_DIR))} images\")\n",
        "print(f\"Original Healthy directory has {len(os.listdir(healthy_SRC_DIR))} images\")\n",
        "print(f\"Original Monilia directory has {len(os.listdir(monilia_SRC_DIR))} images\\n\")\n",
        "\n",
        "# Training and validation splits\n",
        "print(f\"There are {len(os.listdir(TRAINING_BPR_DIR))} images of Black Pod Rot for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_HEALTHY_DIR))} images ofHealthy for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_M_DIR))} images of Monilia for training\\n\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(VALIDATION_BPR_DIR))} images of Black Pod Rot for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_HEALTHY_DIR))} images of Healthy for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_M_DIR))} images of Monilia for validation\\n\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(TEST_BPR_DIR))} images of Black Pod Rot for test\")\n",
        "print(f\"There are {len(os.listdir(TEST_HEALTHY_DIR))} images of Healthy for test\")\n",
        "print(f\"There are {len(os.listdir(TEST_M_DIR))} images of Monilia for test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5b716060",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:44.341791Z",
          "iopub.status.busy": "2023-06-14T14:27:44.341396Z",
          "iopub.status.idle": "2023-06-14T14:27:44.356759Z",
          "shell.execute_reply": "2023-06-14T14:27:44.355808Z"
        },
        "id": "5b716060",
        "papermill": {
          "duration": 0.034785,
          "end_time": "2023-06-14T14:27:44.359909",
          "exception": false,
          "start_time": "2023-06-14T14:27:44.325124",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path_to_train_data_directory'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Directorio de datos de entrenamiento\u001b[39;00m\n\u001b[1;32m     12\u001b[0m train_data_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpath_to_train_data_directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m train_dataset \u001b[39m=\u001b[39m ImageFolder(train_data_dir, transform\u001b[39m=\u001b[39;49mimage_transforms)\n\u001b[1;32m     14\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Definir el modelo\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    310\u001b[0m         root,\n\u001b[1;32m    311\u001b[0m         loader,\n\u001b[1;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[1;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[1;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/torchvision/datasets/folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[1;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/torchvision/datasets/folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[1;32m    192\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/torchvision/datasets/folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m     42\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_train_data_directory'"
          ]
        }
      ],
      "source": [
        "# Copiar archivos de una carpeta a otra\n",
        "def copyfile(src, dst):\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "# Crear un generador de imágenes\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((250, 250)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Directorio de datos de entrenamiento\n",
        "train_data_dir = \"path_to_train_data_directory\"\n",
        "train_dataset = ImageFolder(train_data_dir, transform=image_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38772c6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Definir el modelo\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * 30 * 30, 128)\n",
        "        self.fc2 = nn.Linear(128, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(bn1(relu(conv1(x))))\n",
        "        x = self.pool2(bn2(relu(conv2(x))))\n",
        "        x = self.pool3(bn3(relu(conv3(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc2(relu(fc1(x)))\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Instanciar el modelo\n",
        "model = CustomModel()\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "# Guardar el modelo\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "'''\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "                                    rescale=1. / 255,\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest'\n",
        "                                     )\n",
        "    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=10,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      target_size=(250,250))\n",
        "    validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "    validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=10,\n",
        "                                                                class_mode='categorical',\n",
        "                                                                target_size=(250,250))\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "    test_generator = test_datagen.flow_from_directory(directory=TEST_DIR,\n",
        "                                                                batch_size=10,\n",
        "                                                                class_mode='categorical',\n",
        "                                                                target_size=(250,250),\n",
        "                                                                shuffle=False)\n",
        "    return train_generator, validation_generator, test_generator\n",
        "\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9258937a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:44.403689Z",
          "iopub.status.busy": "2023-06-14T14:27:44.403206Z",
          "iopub.status.idle": "2023-06-14T14:27:44.594852Z",
          "shell.execute_reply": "2023-06-14T14:27:44.593620Z"
        },
        "id": "9258937a",
        "papermill": {
          "duration": 0.214906,
          "end_time": "2023-06-14T14:27:44.598392",
          "exception": false,
          "start_time": "2023-06-14T14:27:44.383486",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_generator, validation_generator, test_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "635c4b0c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:44.639454Z",
          "iopub.status.busy": "2023-06-14T14:27:44.638961Z",
          "iopub.status.idle": "2023-06-14T14:27:44.645791Z",
          "shell.execute_reply": "2023-06-14T14:27:44.644381Z"
        },
        "id": "635c4b0c",
        "papermill": {
          "duration": 0.029003,
          "end_time": "2023-06-14T14:27:44.650791",
          "exception": false,
          "start_time": "2023-06-14T14:27:44.621788",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Print label\n",
        "class_labels = train_generator.class_indices\n",
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd044318",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:44.694410Z",
          "iopub.status.busy": "2023-06-14T14:27:44.693884Z",
          "iopub.status.idle": "2023-06-14T14:27:44.711058Z",
          "shell.execute_reply": "2023-06-14T14:27:44.709894Z"
        },
        "id": "bd044318",
        "papermill": {
          "duration": 0.047887,
          "end_time": "2023-06-14T14:27:44.714625",
          "exception": false,
          "start_time": "2023-06-14T14:27:44.666738",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(250,250,3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a071f048",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:44.754171Z",
          "iopub.status.busy": "2023-06-14T14:27:44.753155Z",
          "iopub.status.idle": "2023-06-14T14:27:48.222483Z",
          "shell.execute_reply": "2023-06-14T14:27:48.221489Z"
        },
        "id": "a071f048",
        "papermill": {
          "duration": 3.517384,
          "end_time": "2023-06-14T14:27:48.250207",
          "exception": false,
          "start_time": "2023-06-14T14:27:44.732823",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5dcafd2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T14:27:50.107471Z",
          "iopub.status.busy": "2023-06-14T14:27:50.106837Z",
          "iopub.status.idle": "2023-06-14T15:07:20.936493Z",
          "shell.execute_reply": "2023-06-14T15:07:20.935488Z"
        },
        "id": "f5dcafd2",
        "papermill": {
          "duration": 2370.86741,
          "end_time": "2023-06-14T15:07:20.938898",
          "exception": false,
          "start_time": "2023-06-14T14:27:50.071488",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Train\n",
        "\n",
        "\n",
        "# create checkpoint\n",
        "checkpoint = ModelCheckpoint('model_tertinggi.h5', monitor='accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=30,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e505f2c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:22.315238Z",
          "iopub.status.busy": "2023-06-14T15:07:22.314156Z",
          "iopub.status.idle": "2023-06-14T15:07:22.794368Z",
          "shell.execute_reply": "2023-06-14T15:07:22.793487Z"
        },
        "id": "8e505f2c",
        "papermill": {
          "duration": 1.203091,
          "end_time": "2023-06-14T15:07:22.798636",
          "exception": false,
          "start_time": "2023-06-14T15:07:21.595545",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Mendapatkan satu batch gambar dari train_generator\n",
        "batch = train_generator.next()\n",
        "\n",
        "# Mendapatkan array gambar dan labelnya dari batch\n",
        "images = batch[0]\n",
        "labels = batch[1]\n",
        "\n",
        "# Memilih indeks acak untuk menampilkan gambar\n",
        "random_index = np.random.randint(0, images.shape[0])\n",
        "\n",
        "# Mengambil gambar dan label dengan indeks acak\n",
        "image = images[random_index]\n",
        "label = labels[random_index]\n",
        "\n",
        "# Menampilkan gambar\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Label: {label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d60f1d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:24.583398Z",
          "iopub.status.busy": "2023-06-14T15:07:24.583016Z",
          "iopub.status.idle": "2023-06-14T15:07:24.850397Z",
          "shell.execute_reply": "2023-06-14T15:07:24.849509Z"
        },
        "id": "2d60f1d0",
        "papermill": {
          "duration": 1.216342,
          "end_time": "2023-06-14T15:07:24.852522",
          "exception": false,
          "start_time": "2023-06-14T15:07:23.636180",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot train loss dan validation loss\n",
        "plt.plot(epochs, train_loss, 'r', label='Train Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Train Loss vs Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aef54d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:26.242156Z",
          "iopub.status.busy": "2023-06-14T15:07:26.241798Z",
          "iopub.status.idle": "2023-06-14T15:07:26.495164Z",
          "shell.execute_reply": "2023-06-14T15:07:26.494252Z"
        },
        "id": "7aef54d6",
        "papermill": {
          "duration": 0.923386,
          "end_time": "2023-06-14T15:07:26.497253",
          "exception": false,
          "start_time": "2023-06-14T15:07:25.573867",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "plt.plot(epochs, train_accuracy, 'g', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5807de52",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:27.903758Z",
          "iopub.status.busy": "2023-06-14T15:07:27.903397Z",
          "iopub.status.idle": "2023-06-14T15:07:34.293178Z",
          "shell.execute_reply": "2023-06-14T15:07:34.292148Z"
        },
        "id": "5807de52",
        "papermill": {
          "duration": 7.059769,
          "end_time": "2023-06-14T15:07:34.295203",
          "exception": false,
          "start_time": "2023-06-14T15:07:27.235434",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aef48a3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:35.634879Z",
          "iopub.status.busy": "2023-06-14T15:07:35.633967Z",
          "iopub.status.idle": "2023-06-14T15:07:35.890607Z",
          "shell.execute_reply": "2023-06-14T15:07:35.889538Z"
        },
        "id": "9aef48a3",
        "papermill": {
          "duration": 0.926839,
          "end_time": "2023-06-14T15:07:35.892675",
          "exception": false,
          "start_time": "2023-06-14T15:07:34.965836",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fungsi untuk melakukan prediksi pada file gambar\n",
        "def predict_image(file):\n",
        "    img = image.load_img(file, target_size=(250, 250))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255.0\n",
        "    prediction = model_terbaik.predict(img)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    predicted_probability = np.max(prediction)\n",
        "\n",
        "    return predicted_class_index, predicted_probability\n",
        "\n",
        "#file\n",
        "uploaded_file = '/kaggle/input/test-data/test cocoa/black_pod_rot/black_pod_rot_94.jpg'\n",
        "\n",
        "#prediksi pada file gambar\n",
        "predicted_class_index,  predicted_probability = predict_image(uploaded_file)\n",
        "\n",
        "if predicted_class_index == 0:\n",
        "    hasil = 'Back Pod Rot'\n",
        "elif predicted_class_index == 1:\n",
        "    hasil = 'Healthy'\n",
        "else:\n",
        "    hasil = 'Pod Borer'\n",
        "\n",
        "print(\"Hasil prediksi:\", hasil)\n",
        "print(\"Probabilitas prediksi:\", predicted_probability)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f63e65f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:37.300995Z",
          "iopub.status.busy": "2023-06-14T15:07:37.300241Z",
          "iopub.status.idle": "2023-06-14T15:07:43.434960Z",
          "shell.execute_reply": "2023-06-14T15:07:43.432926Z"
        },
        "id": "6f63e65f",
        "papermill": {
          "duration": 6.810082,
          "end_time": "2023-06-14T15:07:43.437122",
          "exception": false,
          "start_time": "2023-06-14T15:07:36.627040",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Mengumpulkan prediksi model untuk data uji\n",
        "y_pred = model_terbaik.predict(test_generator)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Mengambil label sebenarnya dari generator\n",
        "y_true_labels = test_generator.classes\n",
        "\n",
        "# Mendapatkan nama kelas dari generator\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Membuat classification report\n",
        "report = classification_report(y_true_labels, y_pred_labels, target_names=class_names)\n",
        "\n",
        "# Menampilkan classification report\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74909022",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:44.786713Z",
          "iopub.status.busy": "2023-06-14T15:07:44.785753Z",
          "iopub.status.idle": "2023-06-14T15:07:44.794843Z",
          "shell.execute_reply": "2023-06-14T15:07:44.793962Z"
        },
        "id": "74909022",
        "papermill": {
          "duration": 0.68092,
          "end_time": "2023-06-14T15:07:44.796823",
          "exception": false,
          "start_time": "2023-06-14T15:07:44.115903",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "y_true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089563b5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:46.197848Z",
          "iopub.status.busy": "2023-06-14T15:07:46.197221Z",
          "iopub.status.idle": "2023-06-14T15:07:46.205468Z",
          "shell.execute_reply": "2023-06-14T15:07:46.204507Z"
        },
        "id": "089563b5",
        "papermill": {
          "duration": 0.685674,
          "end_time": "2023-06-14T15:07:46.207449",
          "exception": false,
          "start_time": "2023-06-14T15:07:45.521775",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "y_pred_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e328fe",
      "metadata": {
        "id": "b3e328fe",
        "papermill": {
          "duration": 0.723166,
          "end_time": "2023-06-14T15:07:47.599931",
          "exception": false,
          "start_time": "2023-06-14T15:07:46.876765",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**For Deploying**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518959bb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:49.035435Z",
          "iopub.status.busy": "2023-06-14T15:07:49.035051Z",
          "iopub.status.idle": "2023-06-14T15:07:49.039493Z",
          "shell.execute_reply": "2023-06-14T15:07:49.038489Z"
        },
        "id": "518959bb",
        "papermill": {
          "duration": 0.761558,
          "end_time": "2023-06-14T15:07:49.042057",
          "exception": false,
          "start_time": "2023-06-14T15:07:48.280499",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f93a0e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:50.489029Z",
          "iopub.status.busy": "2023-06-14T15:07:50.488668Z",
          "iopub.status.idle": "2023-06-14T15:07:50.493092Z",
          "shell.execute_reply": "2023-06-14T15:07:50.492182Z"
        },
        "id": "37f93a0e",
        "papermill": {
          "duration": 0.706501,
          "end_time": "2023-06-14T15:07:50.495085",
          "exception": false,
          "start_time": "2023-06-14T15:07:49.788584",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# import tensorflowjs as tfjs\n",
        "\n",
        "# # Load model .h5\n",
        "# model = tf.keras.models.load_model('model_tertinggi.h5')\n",
        "\n",
        "# # Konversi model .h5 ke TensorFlow.js\n",
        "# tfjs.converters.save_keras_model(model, 'FIX DEPLOY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbeb3d6b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-14T15:07:51.918904Z",
          "iopub.status.busy": "2023-06-14T15:07:51.918544Z",
          "iopub.status.idle": "2023-06-14T15:07:51.923317Z",
          "shell.execute_reply": "2023-06-14T15:07:51.922361Z"
        },
        "id": "fbeb3d6b",
        "papermill": {
          "duration": 0.751403,
          "end_time": "2023-06-14T15:07:51.925463",
          "exception": false,
          "start_time": "2023-06-14T15:07:51.174060",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "# import zipfile\n",
        "\n",
        "# def create_zip_folder(folder_path, zip_file_path):\n",
        "#     # Membuat file ZIP dari folder\n",
        "#     shutil.make_archive(zip_file_path, 'zip', folder_path)\n",
        "\n",
        "# # Contoh penggunaan\n",
        "# folder_path = '/kaggle/working/FIX DEPLOY'  # Ganti dengan path folder yang diinginkan\n",
        "# zip_file_path = '/kaggle/working/zipfile.zip'  # Ganti dengan path file ZIP yang ingin Anda buat\n",
        "# create_zip_folder(folder_path, zip_file_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2464.969698,
      "end_time": "2023-06-14T15:07:56.810465",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-06-14T14:26:51.840767",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
